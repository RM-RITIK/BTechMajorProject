{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:09:09.775124Z",
     "start_time": "2020-04-03T01:09:09.635505Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-22T08:16:43.294288Z",
     "iopub.status.busy": "2021-12-22T08:16:43.293658Z",
     "iopub.status.idle": "2021-12-22T08:16:44.845633Z",
     "shell.execute_reply": "2021-12-22T08:16:44.844526Z",
     "shell.execute_reply.started": "2021-12-22T08:16:43.294234Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint \n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLOOP is a python package that provides a convenient interface for exploring and analyzing text data. \n",
    "Behind the scene, NLOOP uses spaCy and gensim to take care of cleaning, tokenization, dependency parsing, keyword extraction and much more in one fell swoop. Here I will use it to build a keyword co-occurrence graph from the titles and abstracts of the research papers in the provided dataset. \n",
    "\n",
    "You can install NLOOP from the following address. Checkout the github repository for more examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-22T08:16:49.213364Z",
     "iopub.status.busy": "2021-12-22T08:16:49.213046Z",
     "iopub.status.idle": "2021-12-22T08:17:31.897143Z",
     "shell.execute_reply": "2021-12-22T08:17:31.896343Z",
     "shell.execute_reply.started": "2021-12-22T08:16:49.213334Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/syasini/NLOOP.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:17:31.899279Z",
     "iopub.status.busy": "2021-12-22T08:17:31.898963Z",
     "iopub.status.idle": "2021-12-22T08:17:36.877318Z",
     "shell.execute_reply": "2021-12-22T08:17:36.876481Z",
     "shell.execute_reply.started": "2021-12-22T08:17:31.899233Z"
    }
   },
   "outputs": [],
   "source": [
    "from nloop import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:09:14.7825Z",
     "start_time": "2020-04-03T01:09:13.976048Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-22T08:17:46.710245Z",
     "iopub.status.busy": "2021-12-22T08:17:46.709960Z",
     "iopub.status.idle": "2021-12-22T08:17:46.816019Z",
     "shell.execute_reply": "2021-12-22T08:17:46.814868Z",
     "shell.execute_reply.started": "2021-12-22T08:17:46.710218Z"
    }
   },
   "outputs": [],
   "source": [
    "data_fname = os.path.join(\"..\",\"input\",\"project-btech\", \"dataset.csv\")\n",
    "data = pd.read_csv(data_fname, index_col=0,)\n",
    "\n",
    " # let's look at a small sample of the data \n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:41:38.082268Z",
     "start_time": "2020-04-03T01:09:26.716987Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-22T08:18:01.185027Z",
     "iopub.status.busy": "2021-12-22T08:18:01.184523Z",
     "iopub.status.idle": "2021-12-22T08:18:50.849246Z",
     "shell.execute_reply": "2021-12-22T08:18:50.848523Z",
     "shell.execute_reply.started": "2021-12-22T08:18:01.184978Z"
    }
   },
   "outputs": [],
   "source": [
    "# process text with nloop\n",
    "text = Text(data[\"text\"], fast=False)\n",
    "\n",
    "# This will take a while for the entire corpus\n",
    "# use fast=True if you're only interested in clean tokens\n",
    "# and don't need dependencies, named entities, and keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:42:18.199896Z",
     "start_time": "2020-04-03T01:41:50.820084Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-22T08:19:29.005407Z",
     "iopub.status.busy": "2021-12-22T08:19:29.005044Z",
     "iopub.status.idle": "2021-12-22T08:19:30.112669Z",
     "shell.execute_reply": "2021-12-22T08:19:30.111993Z",
     "shell.execute_reply.started": "2021-12-22T08:19:29.005358Z"
    }
   },
   "outputs": [],
   "source": [
    "# show word cloud\n",
    "text.show_wordcloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:42:25.284982Z",
     "start_time": "2020-04-03T01:42:24.340335Z"
    },
    "execution": {
     "iopub.execute_input": "2021-12-22T08:19:36.455332Z",
     "iopub.status.busy": "2021-12-22T08:19:36.454860Z",
     "iopub.status.idle": "2021-12-22T08:19:36.519916Z",
     "shell.execute_reply": "2021-12-22T08:19:36.518803Z",
     "shell.execute_reply.started": "2021-12-22T08:19:36.455300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show the most common token\n",
    "text_tokens = []\n",
    "for i in range (0, len(text.tokens)):\n",
    "    for j in range (0, len(text.tokens[i])):\n",
    "        text_tokens.append(text.tokens[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Deep Walk </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:23:45.300099Z",
     "iopub.status.busy": "2021-12-22T08:23:45.299697Z",
     "iopub.status.idle": "2021-12-22T08:23:45.366285Z",
     "shell.execute_reply": "2021-12-22T08:23:45.365550Z",
     "shell.execute_reply.started": "2021-12-22T08:23:45.300067Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv') #only for local computer\n",
    "text = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:24:29.118426Z",
     "iopub.status.busy": "2021-12-22T08:24:29.117963Z",
     "iopub.status.idle": "2021-12-22T08:24:30.557240Z",
     "shell.execute_reply": "2021-12-22T08:24:30.556059Z",
     "shell.execute_reply.started": "2021-12-22T08:24:29.118374Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 4 ... 0 0 0]\n",
      " [0 4 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "docs = text\n",
    "count_model = CountVectorizer(ngram_range=(1,1)) # default unigram model\n",
    "X = count_model.fit_transform(docs)\n",
    "# X[X > 0] = 1 # run this line if you don't want extra within-text cooccurence (see below)\n",
    "Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
    "Xc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\n",
    "print(Xc.todense()) # print out matrix in dense format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:24:34.468118Z",
     "iopub.status.busy": "2021-12-22T08:24:34.467671Z",
     "iopub.status.idle": "2021-12-22T08:24:34.522707Z",
     "shell.execute_reply": "2021-12-22T08:24:34.521763Z",
     "shell.execute_reply.started": "2021-12-22T08:24:34.468087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appendix'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = count_model.get_feature_names()\n",
    "words[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:24:35.834702Z",
     "iopub.status.busy": "2021-12-22T08:24:35.834414Z",
     "iopub.status.idle": "2021-12-22T08:24:35.877265Z",
     "shell.execute_reply": "2021-12-22T08:24:35.876292Z",
     "shell.execute_reply.started": "2021-12-22T08:24:35.834674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9929, 9929)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:24:38.374025Z",
     "iopub.status.busy": "2021-12-22T08:24:38.373464Z",
     "iopub.status.idle": "2021-12-22T08:27:07.169830Z",
     "shell.execute_reply": "2021-12-22T08:27:07.168760Z",
     "shell.execute_reply.started": "2021-12-22T08:24:38.373993Z"
    }
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "mat = Xc.toarray()\n",
    "for i in range (0, 9929):\n",
    "    for j in range(0, 9929):\n",
    "        if mat[i][j] != 0:\n",
    "            G.add_edge(words[i], words[j], weight = mat[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> First Method </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:27:21.952196Z",
     "iopub.status.busy": "2021-12-22T08:27:21.951892Z",
     "iopub.status.idle": "2021-12-22T08:27:22.045249Z",
     "shell.execute_reply": "2021-12-22T08:27:22.044415Z",
     "shell.execute_reply.started": "2021-12-22T08:27:21.952166Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the node sizes using arbitrary transformation \n",
    "node_sizes= [20*G.degree[node]**2+100 for node in G.nodes]\n",
    "\n",
    "# construct the label dictionary\n",
    "labels = {i:i for i in list(G.nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:28:14.254808Z",
     "iopub.status.busy": "2021-12-22T08:28:14.254136Z",
     "iopub.status.idle": "2021-12-22T08:28:14.300326Z",
     "shell.execute_reply": "2021-12-22T08:28:14.299410Z",
     "shell.execute_reply.started": "2021-12-22T08:28:14.254757Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "def get_random_walk(graph:nx.Graph, node:int, n_steps:int = 4)->List[str]:\n",
    "   local_path = [str(node),]\n",
    "   target_node = node\n",
    "   for _ in range(n_steps):\n",
    "      neighbors = list(nx.all_neighbors(graph, target_node))\n",
    "      if len(neighbors) != 0:\n",
    "          target_node = random.choice(neighbors)\n",
    "          local_path.append(str(target_node))\n",
    "   return local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:28:16.295035Z",
     "iopub.status.busy": "2021-12-22T08:28:16.294718Z",
     "iopub.status.idle": "2021-12-22T08:28:23.758099Z",
     "shell.execute_reply": "2021-12-22T08:28:23.757282Z",
     "shell.execute_reply.started": "2021-12-22T08:28:16.294985Z"
    }
   },
   "outputs": [],
   "source": [
    "walk_paths = []\n",
    "for node in G.nodes():\n",
    "   for _ in range(10):\n",
    "      walk_paths.append(get_random_walk(G, node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:28:36.702081Z",
     "iopub.status.busy": "2021-12-22T08:28:36.701773Z",
     "iopub.status.idle": "2021-12-22T08:28:36.743178Z",
     "shell.execute_reply": "2021-12-22T08:28:36.742374Z",
     "shell.execute_reply.started": "2021-12-22T08:28:36.702049Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:28:43.039288Z",
     "iopub.status.busy": "2021-12-22T08:28:43.038948Z",
     "iopub.status.idle": "2021-12-22T08:28:49.843220Z",
     "shell.execute_reply": "2021-12-22T08:28:49.842501Z",
     "shell.execute_reply.started": "2021-12-22T08:28:43.039259Z"
    }
   },
   "outputs": [],
   "source": [
    "embedder = Word2Vec(\n",
    "   window=4, sg=1, hs=0, negative=10, alpha=0.03, min_alpha=0.0001,    \n",
    "   seed=42\n",
    ")\n",
    "embedder.build_vocab(walk_paths, progress_per=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:32:14.923583Z",
     "iopub.status.busy": "2021-12-22T08:32:14.923056Z",
     "iopub.status.idle": "2021-12-22T08:32:14.986339Z",
     "shell.execute_reply": "2021-12-22T08:32:14.985351Z",
     "shell.execute_reply.started": "2021-12-22T08:32:14.923539Z"
    }
   },
   "outputs": [],
   "source": [
    "embedder.similar_by_word('glass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:32:09.893642Z",
     "iopub.status.busy": "2021-12-22T08:32:09.893239Z",
     "iopub.status.idle": "2021-12-22T08:32:09.944469Z",
     "shell.execute_reply": "2021-12-22T08:32:09.943339Z",
     "shell.execute_reply.started": "2021-12-22T08:32:09.893606Z"
    }
   },
   "outputs": [],
   "source": [
    "len(embedder['rules'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:37:10.417736Z",
     "iopub.status.busy": "2021-12-22T08:37:10.417408Z",
     "iopub.status.idle": "2021-12-22T08:37:10.537240Z",
     "shell.execute_reply": "2021-12-22T08:37:10.536607Z",
     "shell.execute_reply.started": "2021-12-22T08:37:10.417705Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "embeddings = []\n",
    "for word in words:\n",
    "    embeddings.append(embedder[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:40:48.715214Z",
     "iopub.status.busy": "2021-12-22T08:40:48.714989Z",
     "iopub.status.idle": "2021-12-22T08:40:48.758944Z",
     "shell.execute_reply": "2021-12-22T08:40:48.757932Z",
     "shell.execute_reply.started": "2021-12-22T08:40:48.715189Z"
    }
   },
   "outputs": [],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:40:05.241553Z",
     "iopub.status.busy": "2021-12-22T08:40:05.240911Z",
     "iopub.status.idle": "2021-12-22T08:40:05.292927Z",
     "shell.execute_reply": "2021-12-22T08:40:05.292075Z",
     "shell.execute_reply.started": "2021-12-22T08:40:05.241505Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['words'] = words\n",
    "df['embeddings'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T08:41:27.769214Z",
     "iopub.status.busy": "2021-12-22T08:41:27.768856Z",
     "iopub.status.idle": "2021-12-22T08:41:41.012326Z",
     "shell.execute_reply": "2021-12-22T08:41:41.011354Z",
     "shell.execute_reply.started": "2021-12-22T08:41:27.769164Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('DeepWalkEmbeddings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Second Method </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting karateclub\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/82/80e6d419a76fa57069b09b929cb8628e2aca8e50a00aa2bfa081b2239351/karateclub-1.2.2.tar.gz (62kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 551kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/ritik/anaconda3/lib/python3.7/site-packages (from karateclub) (1.20.1)\n",
      "Requirement already satisfied: networkx in /Users/ritik/anaconda3/lib/python3.7/site-packages (from karateclub) (2.2)\n",
      "Collecting decorator==4.4.2 (from karateclub)\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/1b/72a1821152d07cf1d8b6fce298aeb06a7eb90f4d6d41acec9861e7cc6df0/decorator-4.4.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /Users/ritik/anaconda3/lib/python3.7/site-packages (from karateclub) (4.28.1)\n",
      "Collecting python-louvain (from karateclub)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/5a/8a6d1210e3c26d5912a538097d4bc749222fd2c69a014505fbeec6b185c9/python-louvain-0.15.tar.gz (204kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 955kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /Users/ritik/anaconda3/lib/python3.7/site-packages (from karateclub) (0.20.1)\n",
      "Requirement already satisfied: scipy in /Users/ritik/anaconda3/lib/python3.7/site-packages (from karateclub) (1.1.0)\n",
      "Collecting pygsp (from karateclub)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/89/2f4aa73cccf12bec5179ac5d52a68b508120c838b7e5d456f5ea0c8beade/PyGSP-0.5.1-py2.py3-none-any.whl (1.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.8MB 2.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting gensim>=4.0.0 (from karateclub)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/e0/6c4123d6bf463160f9ef6d9ea4336c71b99cb0591d94b5cce719a7d7a80d/gensim-4.1.2-cp37-cp37m-macosx_10_9_x86_64.whl (24.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.0MB 294kB/s ta 0:00:011    94% |██████████████████████████████▎ | 22.7MB 987kB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/ritik/anaconda3/lib/python3.7/site-packages (from karateclub) (1.2.3)\n",
      "Requirement already satisfied: six in /Users/ritik/anaconda3/lib/python3.7/site-packages (from karateclub) (1.12.0)\n",
      "Collecting python-Levenshtein (from karateclub)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 336kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim>=4.0.0->karateclub)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/11/05f68ea934c24ade38e95ac30a38407767787c4e3db1776eae4886ad8c95/smart_open-5.2.1-py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 2.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/ritik/anaconda3/lib/python3.7/site-packages (from pandas->karateclub) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/ritik/anaconda3/lib/python3.7/site-packages (from pandas->karateclub) (2018.7)\n",
      "Requirement already satisfied: setuptools in /Users/ritik/anaconda3/lib/python3.7/site-packages (from python-Levenshtein->karateclub) (46.1.3)\n",
      "Building wheels for collected packages: karateclub, python-louvain, python-Levenshtein\n",
      "  Running setup.py bdist_wheel for karateclub ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/ritik/Library/Caches/pip/wheels/df/fe/2c/354f0b8f7070de4b906898a24a1a6fd2d2229273076f061b0a\n",
      "  Running setup.py bdist_wheel for python-louvain ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/ritik/Library/Caches/pip/wheels/cb/a8/eb/20aa8acb5ad4c23a72b7d4159adc75202243a4106a738981b7\n",
      "  Running setup.py bdist_wheel for python-Levenshtein ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/ritik/Library/Caches/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
      "Successfully built karateclub python-louvain python-Levenshtein\n",
      "Installing collected packages: decorator, python-louvain, pygsp, smart-open, gensim, python-Levenshtein, karateclub\n",
      "  Found existing installation: decorator 4.3.0\n",
      "    Uninstalling decorator-4.3.0:\n",
      "      Successfully uninstalled decorator-4.3.0\n",
      "Successfully installed decorator-4.4.2 gensim-4.1.2 karateclub-1.2.2 pygsp-0.5.1 python-Levenshtein-0.12.2 python-louvain-0.15 smart-open-5.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip install karateclub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "/Users/ritik/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "from karateclub import DeepWalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepWalk(walk_length=100, dimensions=768, window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_num = nx.convert_node_labels_to_integers(G, first_label=0, ordering='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(graph_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
